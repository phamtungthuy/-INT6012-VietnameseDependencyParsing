# Vietnamese Dependency Parsing

BiLSTM + Biaffine Attention model for Vietnamese Dependency Parsing.

## ğŸ“ Project Structure

```
vietnamese_dependency_parsing/
â”œâ”€â”€ configs/                 # Training configuration
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ data/                    # CoNLL-U data files
â”‚   â”œâ”€â”€ vi_vtb-ud-train.conllu
â”‚   â”œâ”€â”€ vi_vtb-ud-dev.conllu
â”‚   â””â”€â”€ vi_vtb-ud-test.conllu
â”œâ”€â”€ data_processing/         # Data processing modules
â”‚   â”œâ”€â”€ loader.py           # CoNLL-U file loader
â”‚   â”œâ”€â”€ vocabulary.py       # Vocabulary builder
â”‚   â”œâ”€â”€ dependency.py       # PyTorch Dataset
â”‚   â””â”€â”€ analyzer.py         # Data analysis tools
â”œâ”€â”€ models/                  # Model definitions
â”‚   â”œâ”€â”€ attention/          # Attention layers
â”‚   â”‚   â”œâ”€â”€ base_attention.py
â”‚   â”‚   â””â”€â”€ biaffine_attention.py
â”‚   â””â”€â”€ parser/             # Parser models
â”‚       â”œâ”€â”€ base_parser.py
â”‚       â””â”€â”€ bilstm_parser.py
â”œâ”€â”€ training/               # Training logic
â”‚   â”œâ”€â”€ trainer.py
â”‚   â””â”€â”€ train_config.py
â”œâ”€â”€ evaluation/             # Evaluation metrics
â”‚   â””â”€â”€ evaluator.py
â”œâ”€â”€ scripts/                # CLI scripts
â”‚   â”œâ”€â”€ cli.py             # CLI entry points
â”‚   â”œâ”€â”€ train.py           # Training script
â”‚   â”œâ”€â”€ visualization.py   # Visualization server
â”‚   â””â”€â”€ demo.py            # Demo server
â”œâ”€â”€ templates/              # HTML templates
â”‚   â”œâ”€â”€ visualization.html
â”‚   â””â”€â”€ demo.html
â”œâ”€â”€ checkpoints/            # Saved model checkpoints
â”œâ”€â”€ results/                # Training results
â””â”€â”€ logs/                   # Log files
```

## ğŸš€ Installation

### 1. Create Virtual Environment

```bash
# Create virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Activate (Linux/Mac)
source venv/bin/activate
```

### 2. Install Package

```bash
# Install in editable mode
pip install -e .
```

This will:
- Install all dependencies (torch, numpy, tqdm, flask, ...)
- Register CLI commands: `train`, `visualize`, `demo`, `analyze`

## ğŸ’» Usage

### Data Analysis

Analyze dataset to find optimal `min_freq` value:

```bash
analyze
```

Output:
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         MIN_FREQ ANALYSIS REPORT                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Dataset Statistics:
   Train sentences: 1,400
   Dev sentences:   1,123
   Test sentences:  800

ğŸ” Min_freq Analysis:
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ min_freqâ”‚ Vocab Size â”‚ Coverage  â”‚ OOV Rate â”‚ Unique OOV â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚       1 â”‚      3,401 â”‚    100.0% â”‚    15.7% â”‚      3,191 â”‚
   â”‚       2 â”‚      1,649 â”‚     91.3% â”‚    21.0% â”‚      3,884 â”‚
   ...
```

### Training

```bash
# Train with default config from configs/config.yaml
train

# Resume from checkpoint
train --resume checkpoints/checkpoint_epoch_10.pt
```

Training configuration in `configs/config.yaml`:

```yaml
model:
  embedding_dim: 100
  pos_dim: 50
  hidden_dim: 400
  num_layers: 3
  arc_dim: 500
  label_dim: 100
  dropout: 0.33

training:
  batch_size: 32
  num_epochs: 30
  lr: 0.002
  weight_decay: 0.0001
  min_freq: 2
  seed: 42
  save_every: 5

paths:
  save_dir: checkpoints
  results_dir: results

device: cuda  # or cpu
```

### Visualization

Launch web server to visualize dependency trees:

```bash
# Default: http://127.0.0.1:5000
visualize

# Custom host/port
visualize --host 0.0.0.0 --port 8000
```

Features:
- Select dataset (train/dev/test)
- Navigate through sentences
- Jump to specific sentence
- Interactive SVG dependency tree

### Demo

Compare ground truth vs model predictions:

```bash
# Default: http://127.0.0.1:5001
demo

# Custom model checkpoint
demo --model checkpoints/best_model.pt

# Custom host/port
demo --host 0.0.0.0 --port 8001
```

Features:
- Side-by-side ground truth and prediction comparison
- Error highlighting (incorrect arcs in red)
- UAS/LAS statistics
- Custom sentence parsing

## ğŸ“Š Results

Training results are saved in `results/run_YYYYMMDD_HHMMSS/`:

```
results/run_20260113_001411/
â”œâ”€â”€ config.yaml      # Configuration used
â”œâ”€â”€ config.json      # Configuration (JSON format)
â”œâ”€â”€ vocab.pt         # Built vocabulary
â”œâ”€â”€ history.json     # Training history (loss, accuracy per epoch)
â””â”€â”€ results.json     # Final results (UAS, LAS)
```

## ğŸ“ˆ Metrics

- **UAS (Unlabeled Attachment Score)**: Percentage of tokens with correct head prediction
- **LAS (Labeled Attachment Score)**: Percentage of tokens with correct head and relation prediction

## ğŸ”§ Dependencies

- Python >= 3.10
- PyTorch >= 1.8.0
- NumPy >= 1.19.0
- tqdm >= 4.50.0
- conllu == 6.0.0
- loguru == 0.7.3
- PyYAML == 6.0.3
- Flask >= 3.0.0

## ğŸ“š References

1. Dozat, T., & Manning, C. D. (2017). **Deep Biaffine Attention for Neural Dependency Parsing**. *ICLR 2017*.
2. Nguyen, P. T., Vu, X. L., Nguyen, T. M. H., Nguyen, V. H., & Le, H. P. (2009). **Building a Large Syntactically-Annotated Corpus of Vietnamese**. *Proceedings of the Third Linguistic Annotation Workshop (LAW III)*, pages 182-185. [[ACL Anthology]](https://aclanthology.org/W09-3035/)

## ğŸ™ Acknowledgements

This project is built upon the following works:

### Core Architecture
- **Biaffine Attention**: Dozat & Manning (2017) - "Deep Biaffine Attention for Neural Dependency Parsing"

### Data
- **Vietnamese Treebank (VTB)**: Nguyen et al. (2009) - "Building a Large Syntactically-Annotated Corpus of Vietnamese"

### Other References
<!-- Add more references as needed -->
<!--
- Author et al. (Year). "Paper Title". Conference/Journal.
-->

## ğŸ“ License

MIT License
